# ─────────────────────────────────────────────────────────────────────────────
# Real-Time Streaming Workspace Configuration Template
# Optimized for: IoT telemetry, real-time event processing, live dashboards
# Use Cases: IoT platforms, clickstream analytics, fraud detection, alerting
# Strategy: Git-sync-only — Fabric items managed through Git, not CLI
# ─────────────────────────────────────────────────────────────────────────────

workspace:
  name: "streaming-workspace"         # ← CHANGE: Your project workspace name
  display_name: "Real-Time Streaming Platform"
  description: "Event-driven analytics with real-time ingestion and alerting"
  capacity_id: "${FABRIC_CAPACITY_ID}"
  domain: "${FABRIC_DOMAIN_NAME}"

  # Git Integration
  git_repo: "${GIT_REPO_URL}"
  git_branch: "main"
  git_directory: "/"

environments:
  dev:
    workspace:
      name: "streaming-workspace"
      capacity_id: "${FABRIC_CAPACITY_ID}"
  test:
    workspace:
      capacity_id: "${FABRIC_CAPACITY_ID}"
  prod:
    workspace:
      capacity_id: "${FABRIC_CAPACITY_ID}"

# ── Folder Structure (Numbered Convention) ───────────────────────────────────
folders:
  - "000 Orchestrate"
  - "100 Ingest"
  - "200 Store"
  - "300 Prepare"
  - "400 Model"
  - "500 Visualize"
  - "999 Libraries"
  - "Archive"

# ── Folder Rules (Post-Git-Sync Item Placement) ─────────────────────────────
folder_rules:
  - type: DataPipeline
    folder: "000 Orchestrate"
  - type: DataflowGen2
    folder: "000 Orchestrate"
  - type: Eventstream
    folder: "100 Ingest"
  - type: Lakehouse
    folder: "200 Store"
  - type: Notebook
    folder: "300 Prepare"
  - type: SparkJobDefinition
    folder: "300 Prepare"
  - type: Warehouse
    folder: "400 Model"
  - type: SemanticModel
    folder: "400 Model"
  - type: Report
    folder: "500 Visualize"
  - type: Dashboard
    folder: "500 Visualize"
  - type: Environment
    folder: "999 Libraries"

# ── No Fabric Items — Content Managed Through Git Sync ───────────────────────
# Typical Git-managed items for a real-time streaming project:
#   - Eventstream: iot_telemetry_stream (100 Ingest) — ingests from IoT Hub
#   - Eventstream: clickstream_events (100 Ingest) — web/app event capture
#   - KQLDatabase: realtime_analytics_db (200 Store) — hot-path queries
#   - Lakehouse: streaming_archive (200 Store) — cold-path historical data
#   - Notebook: stream_processor (300 Prepare) — real-time transformations
#   - Notebook: anomaly_detector (300 Prepare) — ML anomaly detection
#   - Pipeline: batch_reconciliation (000 Orchestrate) — batch vs stream check
#   - Reflex: alert_high_latency (100 Ingest) — automated alerting
#   - Reflex: alert_error_spike (100 Ingest) — error rate monitoring
#   - Report: realtime_dashboard (500 Visualize) — live operational view
# ─────────────────────────────────────────────────────────────────────────────
lakehouses: []
notebooks: []
resources: []

# ── Access Control ───────────────────────────────────────────────────────────
principals:
  # 1. Automation Service Principal (runs deployments)
  - id: "${AZURE_CLIENT_ID}"
    role: Contributor
    description: "Automation SP — required for CI/CD deployments"

  # 2. Mandatory Admin security group (IT governance)
  - id: "${ADDITIONAL_ADMIN_PRINCIPAL_ID}"
    role: Admin
    description: "Mandatory governance admin group"

  # 3. Mandatory Contributor security group (support team)
  - id: "${ADDITIONAL_CONTRIBUTOR_PRINCIPAL_ID}"
    role: Contributor
    description: "Mandatory governance contributor group"

  # ── Project-specific principals ────────────────────────────────────────────
  - id: "${PROJECT_ADMIN_ID}"               # ← CHANGE
    role: Admin
    description: "Streaming platform admins"

  - id: "${PROJECT_MEMBERS_ID}"             # ← CHANGE
    role: Member
    description: "Streaming engineers and DevOps team"

# ── Deployment Pipeline ──────────────────────────────────────────────────────
deployment_pipeline:
  pipeline_name: "streaming-pipeline"    # ← CHANGE
  stages:
    development:
      workspace_name: "streaming-workspace"
      capacity_id: "${FABRIC_CAPACITY_ID}"
    test:
      workspace_name: "streaming-workspace [Test]"
      capacity_id: "${FABRIC_CAPACITY_ID}"
    production:
      workspace_name: "streaming-workspace [Production]"
      capacity_id: "${FABRIC_CAPACITY_ID}"

# REAL-TIME STREAMING GUIDANCE:
# ─────────────────────────────────────────────────────────────────────────────
# Architecture Pattern (Lambda):
#   Hot Path: Eventstream → KQL Database → Real-time Dashboards
#   Cold Path: Eventstream → Lakehouse → Notebooks → Warehouse → Reports
#
# Eventstream Sources:
#   - Azure IoT Hub, Event Hubs, Kafka, Custom Apps
#   - Configure via Fabric portal after workspace deployment
#
# KQL Database (Real-Time Analytics):
#   - Sub-second query latency on streaming data
#   - Ideal for operational dashboards and alerting
#
# Reflex (Automated Response):
#   - Configure alert rules on streaming data patterns
#   - Actions: Email, Teams notification, Power Automate flow
#
# Capacity Considerations:
#   - Streaming workloads consume CU continuously
#   - Consider F8+ capacity for production streaming
#   - Monitor CU usage and throttling metrics
