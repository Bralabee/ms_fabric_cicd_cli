# Basic ETL Workspace Configuration Template
# Organization-agnostic template - customize for your needs

workspace:
  name: "analytics-workspace"  # Change this to your project name
  display_name: "Analytics Workspace"
  description: "ETL workspace for data analytics"
  capacity_id: "${FABRIC_CAPACITY_ID}"  # Environment variable substitution
  
  # Git integration (optional)
  git_repo: "${GIT_REPO_URL}"  # Environment variable substitution
  git_branch: "main"
  git_directory: "/"

# Folder structure (medallion architecture)
folders:
  - "Bronze"    # Raw data landing
  - "Silver"    # Cleaned/processed data
  - "Gold"      # Business-ready analytics
  - "Notebooks" # Data processing notebooks
  - "Pipelines" # Data pipelines

# Lakehouses for data storage
lakehouses:
  - name: "raw_data_lakehouse"
    folder: "Bronze"
    description: "Raw data from source systems"
  
  - name: "processed_data_lakehouse"
    folder: "Silver"
    description: "Cleaned and validated data"
  
  - name: "analytics_lakehouse"
    folder: "Gold"
    description: "Business-ready analytics data"

# Data warehouses for analytics
warehouses:
  - name: "analytics_warehouse"
    folder: "Gold"
    description: "Primary analytics warehouse"

# Notebooks for data processing
notebooks:
  - name: "data_ingestion"
    folder: "Notebooks"
    description: "Data ingestion from source systems"
    # file_path: "notebooks/data_ingestion.py"  # Optional: import from file
  
  - name: "data_transformation"

# Security & Access Control
principals:
  - id: "admin@yourcompany.com"
    role: "Admin"
  - id: "developer@yourcompany.com"
    role: "Member"
  - id: "88e55555-5555-5555-5555-555555555555" # Service Principal Object ID
    role: "Contributor"
    folder: "Notebooks"
    description: "Data cleaning and transformation"
  
  - name: "data_quality_checks"
    folder: "Notebooks"
    description: "Data quality validation and monitoring"

# Pipelines for orchestration
pipelines:
  - name: "daily_etl_pipeline"
    folder: "Pipelines"
    description: "Daily ETL orchestration pipeline"

# Generic Resources (Future-proof)
# Use this section for any Fabric item type not explicitly listed above
# Examples: Eventstream, KQLDatabase, Reflex, etc.
resources:
  - type: "Eventstream"
    name: "iot_events"
    description: "Ingestion stream for IoT data"
  
  - type: "KQLDatabase"
    name: "logs_db"
    description: "Real-time logs database"

# Principals (users/service principals) to add to workspace
# NOTE: Use Object IDs (GUIDs) for all principals. Email addresses are not supported.
principals:
  - id: "${DEV_ADMIN_OBJECT_ID}"  # User/Group Object ID
    role: "Admin"
  
  - id: "${DEV_CONTRIBUTOR_OBJECT_ID}"  # User/Group Object ID
    role: "Contributor"
  
  # Service principal for automation
  - id: "${AZURE_CLIENT_ID}"  # Service Principal Object ID (Required)
    role: "Contributor"

  # Mandatory Security Principals
  - id: "${ADDITIONAL_ADMIN_PRINCIPAL_ID}"
    role: "Admin"
    description: "Mandatory Additional Admin"
  
  - id: "${ADDITIONAL_CONTRIBUTOR_PRINCIPAL_ID}"
    role: "Contributor"
    description: "Mandatory Additional Contributor"

# Configuration notes:
# 1. Replace all placeholder values with your organization's details
# 2. Capacity ID should match your Fabric capacity
# 3. Git repository should be accessible with your credentials
# 4. Principal IDs: Use emails for Users, but Object IDs (GUIDs) for Groups and Service Principals
# 5. Remove sections you don't need (e.g., if no Git integration needed)