# Local Deployment Scenario
# Complete guide with all deploy/validate/destroy commands and verification steps

id: local-deployment
title: Deploy Workspaces Using Local Python
description: |
  Master local deployment operations using Make commands and the CLI. Learn to validate configurations,
  deploy workspaces with `make deploy` and `fabric-cicd deploy`, verify deployments in Fabric portal,
  and safely destroy workspaces when needed.
difficulty: beginner
estimated_duration_minutes: 25
category: deployment
order: 3

prerequisites:
  - getting-started
  - project-generation

learning_outcomes:
  - Activate conda environment correctly before any operation
  - "Validate configurations with `make validate` before deployment"
  - "Deploy workspaces with `make deploy` and `fabric-cicd deploy`"
  - Understand idempotent deployment behavior
  - "Verify deployments with `list_workspace_items.py`"
  - "Safely destroy workspaces with `make destroy`"
  - Review audit logs for compliance

tags:
  - deployment
  - cli
  - makefile
  - validate
  - workspace
  - fabric-cicd

related_scenarios:
  - docker-deployment
  - feature-branch-workflows
  - git-integration
  - environment-promotion

steps:
  - id: overview
    title: Local Deployment Overview
    type: info
    content: |
      Local deployment uses your conda environment and `.env` credentials to provision 
      Fabric workspaces directly from your machine.
      
      ## Deployment Flow
      
      ```
      Configuration â†’ Validation â†’ Authentication â†’ Deployment â†’ Verification
      (YAML file)     (syntax)      (credentials)    (API calls)   (portal check)
      ```
      
      ## Three Ways to Deploy
      
      | Method | Command | When to Use |
      |--------|---------|-------------|
      | **Make** | `make deploy config=... env=dev` | Recommended - simplest |
      | **CLI** | `fabric-cicd deploy ... --env dev` | Direct CLI access |
      | **Python** | `python -m usf_fabric_cli.cli deploy ...` | If entry point missing |
      
      ## Key Deployment Commands
      
      | Operation | Make Command |
      |-----------|--------------|
      | Validate | `make validate config=path/to/config.yaml` |
      | Deploy | `make deploy config=path/to/config.yaml env=dev` |
      | Destroy | `make destroy config=path/to/config.yaml env=dev` |
      | Bulk Destroy | `make bulk-destroy file=workspaces.txt` |
    tips:
      - Always validate before deploying
      - Deployments are idempotent (safe to re-run)
      - Check audit logs after every deployment

  - id: activate-environment
    title: "Step 1: Activate Conda Environment"
    type: command
    content: |
      **CRITICAL:** Before ANY deployment operation, ensure your conda environment is active.
      
      This is the #1 cause of deployment failures - running commands in the wrong environment.
      
      ## Verification Steps
      
      1. Check which environment is active
      2. If wrong, activate the correct one
      3. Verify with `conda env list`
    code:
      language: bash
      content: |
        # Check current environment
        conda env list
        # Look for * next to fabric-cli-cicd
        
        # Activate if not active
        conda activate fabric-cli-cicd
        
        # Verify activation
        which python
        # Should show: .../envs/fabric-cli-cicd/bin/python
        
        # Test import
        python -c "import typer; import rich; print('Environment OK')"
    expected_output: |
      # conda env list output:
      # conda environments:
      #
      base                     /home/user/miniconda3
      fabric-cli-cicd       *  /home/user/miniconda3/envs/fabric-cli-cicd
      
      # which python output:
      /home/user/miniconda3/envs/fabric-cli-cicd/bin/python
      
      # Test output:
      Environment OK
    warnings:
      - "`ModuleNotFoundError` = wrong environment is active"
      - "Always check with `conda env list` if you see import errors"
    tips:
      - "Add `conda activate fabric-cli-cicd` to your shell startup script"
      - "Create an alias: `alias fcli='conda activate fabric-cli-cicd'`"

  - id: validate-config
    title: "Step 2: Validate Configuration"
    type: command
    content: |
      **ALWAYS validate before deploying!** Validation catches errors early.
      
      ## What Validation Checks
      
      | Check | What It Validates |
      |-------|-------------------|
      | YAML Syntax | Indentation, structure, quotes |
      | Required Fields | workspace name, capacity_id |
      | Environment Variables | `${VAR}` references resolve |
      | Jinja2 Templates | `{{ env }}` syntax is valid |
      | Reference Integrity | Folders exist for items |
      | No Duplicates | Item names are unique |
    code:
      language: bash
      content: |
        # Validate using Make (RECOMMENDED)
        make validate config=config/projects/acme_corp/sales_analytics.yaml
        
        # Validate using CLI
        fabric-cicd validate config/projects/acme_corp/sales_analytics.yaml
        
        # Validate with specific environment
        fabric-cicd validate config/projects/acme_corp/sales_analytics.yaml --env prod
        
        # Using Python module (if CLI not registered)
        python -m usf_fabric_cli.cli validate config/projects/acme_corp/sales_analytics.yaml
    expected_output: |
      â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
      â•‘              Configuration Validation                        â•‘
      â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      
      Loading: config/projects/acme_corp/sales_analytics.yaml
      
      âœ“ YAML syntax valid
      âœ“ Required fields present
        - workspace.name: acme-sales-analytics-{{ env }}
        - workspace.capacity_id: ${FABRIC_CAPACITY_ID}
      âœ“ Environment variables resolved (4 variables)
        - FABRIC_CAPACITY_ID âœ“
        - GIT_REPO_URL âœ“
        - DEV_ADMIN_OBJECT_ID âœ“
        - DEV_CONTRIBUTOR_OBJECT_ID âœ“
      âœ“ Jinja2 template syntax valid
      âœ“ Folder references valid
      âœ“ No duplicate item names
      
      Resources to be created:
        - Folders: 4
        - Lakehouses: 3
        - Warehouses: 1
        - Notebooks: 3
        - Pipelines: 2
        - Semantic Models: 1
      
      â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      âœ… Configuration is valid!
      â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    tips:
      - Fix ALL validation errors before deploying
      - "Common error: missing `.env` variable - check your `.env` file"
      - Run validation in CI/CD pipelines before deployment steps

  - id: deploy-dev
    title: "Step 3: Deploy to Development Environment"
    type: command
    content: |
      Deploy your workspace to the development environment.
      
      ## What Happens During Deployment
      
      | Step | Description |
      |------|-------------|
      | 1. Load Config | YAML file parsed, env vars resolved |
      | 2. Authenticate | Service Principal token generated |
      | 3. Create Workspace | Workspace created on Fabric capacity |
      | 4. Create Folders | Folder structure created |
      | 5. Create Items | Lakehouses, warehouses, notebooks, etc. |
      | 6. Assign Principals | User/group access configured |
      | 7. Configure Git | Git connection established (if specified) |
      | 8. Write Audit Log | Operation logged to `audit_logs/` |
    code:
      language: bash
      content: |
        # Deploy using Make (RECOMMENDED)
        make deploy config=config/projects/acme_corp/sales_analytics.yaml env=dev
        
        # Deploy using CLI
        fabric-cicd deploy config/projects/acme_corp/sales_analytics.yaml --env dev
        
        # Deploy with diagnostic output (for troubleshooting)
        fabric-cicd deploy config/projects/acme_corp/sales_analytics.yaml --env dev --diagnose
        
        # Dry run (preview only, no changes)
        fabric-cicd deploy config/projects/acme_corp/sales_analytics.yaml --env dev --validate-only
    expected_output: |
      â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
      â•‘               Fabric Workspace Deployment                    â•‘
      â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      
      Configuration: config/projects/acme_corp/sales_analytics.yaml
      Environment: dev
      
      Authenticating...
      âœ“ Authenticated as Service Principal
      
      Creating workspace...
      âœ“ Workspace 'acme-sales-analytics-dev' created
        ID: 12345678-1234-1234-1234-123456789abc
        Capacity: F8
      
      Creating folders...
      âœ“ Folder '01_Bronze' created
      âœ“ Folder '02_Silver' created
      âœ“ Folder '03_Gold' created
      âœ“ Folder '99_Notebooks' created
      
      Creating lakehouses...
      âœ“ Lakehouse 'sales_raw' created in '01_Bronze'
      âœ“ Lakehouse 'sales_curated' created in '02_Silver'
      âœ“ Lakehouse 'sales_gold' created in '03_Gold'
      
      Creating warehouses...
      âœ“ Warehouse 'sales_reporting' created in '03_Gold'
      
      Creating notebooks...
      âœ“ Notebook 'ingest_sales' created in '99_Notebooks'
      âœ“ Notebook 'transform_sales' created in '99_Notebooks'
      âœ“ Notebook 'report_generation' created in '99_Notebooks'
      
      Assigning principals...
      âœ“ Principal 'admin@acme.com' assigned role 'Admin'
      âœ“ Principal 'sales-team@acme.com' assigned role 'Contributor'
      
      Configuring Git integration...
      âœ“ Git repository connected: https://dev.azure.com/acme/...
      âœ“ Branch: main
      
      Writing audit log...
      âœ“ Logged to: audit_logs/fabric_operations_2025-01-15.jsonl
      
      â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      âœ… Deployment completed successfully!
      
      Workspace URL: https://app.fabric.microsoft.com/groups/12345678-...
      Duration: 45.3 seconds
      â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    tips:
      - "Use `--validate-only` to verify config before deployment"
      - "Use `--diagnose` for verbose output when troubleshooting"
      - Note the workspace URL in the output for quick access

  - id: idempotent-behavior
    title: "Understanding Idempotent Deployments"
    type: info
    content: |
      Deployments are **idempotent** - you can run them multiple times safely.
      
      ## Idempotent Behavior
      
      | Current State | Deployment Action | Result |
      |---------------|-------------------|--------|
      | Does not exist | Create | New item created |
      | Exists (same config) | Skip | "Already exists" message |
      | Exists (different config) | Update | Item updated to match config |
      
      ## Why This Matters
      
      - âœ… **Safe to re-run** after failures
      - âœ… **CI/CD friendly** - no special "first run" logic needed
      - âœ… **Configuration drift corrected** - re-running ensures alignment
      - âœ… **No duplicate errors** - existing items are handled gracefully
    code:
      language: bash
      content: |
        # First deployment - creates everything
        make deploy config=config/projects/acme_corp/sales_analytics.yaml env=dev
        
        # Second deployment - reports existing items
        make deploy config=config/projects/acme_corp/sales_analytics.yaml env=dev
        
        # Third deployment after config change - updates changed items
        make deploy config=config/projects/acme_corp/sales_analytics.yaml env=dev
    expected_output: |
      # Second run output:
      â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
      â•‘               Fabric Workspace Deployment                    â•‘
      â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      
      Configuration: config/projects/acme_corp/sales_analytics.yaml
      Environment: dev
      
      âœ“ Authenticated as Service Principal
      
      â„¹ Workspace 'acme-sales-analytics-dev' already exists (ID: 12345678-...)
      
      â„¹ Folder '01_Bronze' already exists
      â„¹ Folder '02_Silver' already exists
      â„¹ Folder '03_Gold' already exists
      â„¹ Folder '99_Notebooks' already exists
      
      â„¹ Lakehouse 'sales_raw' already exists
      â„¹ Lakehouse 'sales_curated' already exists
      â„¹ Lakehouse 'sales_gold' already exists
      
      â„¹ Warehouse 'sales_reporting' already exists
      
      â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      âœ… Deployment completed! (no changes needed)
      â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    tips:
      - Re-run deployments confidently - they won't create duplicates
      - This is the key principle of "Infrastructure as Code"

  - id: verify-portal
    title: "Step 4: Verify Deployment in Fabric Portal"
    type: checkpoint
    content: |
      After deployment, verify your workspace in the Microsoft Fabric portal.
      
      ## Quick Verification Steps
      
      1. **Open the workspace URL** from the deployment output
      2. **Check folder structure** matches your configuration
      3. **Verify all items created** - lakehouses, warehouses, notebooks
      4. **Check access roles** - team members have correct permissions
      5. **Test Git integration** - shows "Connected" status
      
      ## Programmatic Verification
      
      Use the `list_workspace_items.py` utility script:
    code:
      language: bash
      content: |
        # List all items in the deployed workspace
        python scripts/admin/utilities/list_workspace_items.py --workspace "acme-sales-analytics-dev"
        
        # Alternative: List all workspaces first
        python scripts/admin/utilities/list_workspaces.py
    expected_output: |
      Fetching workspace: acme-sales-analytics-dev
      
      â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
      â•‘        Workspace: acme-sales-analytics-dev                   â•‘
      â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      
      Folders:
      â”œâ”€â”€ 01_Bronze
      â”‚   â””â”€â”€ Lakehouse: sales_raw
      â”œâ”€â”€ 02_Silver
      â”‚   â””â”€â”€ Lakehouse: sales_curated
      â”œâ”€â”€ 03_Gold
      â”‚   â”œâ”€â”€ Lakehouse: sales_gold
      â”‚   â””â”€â”€ Warehouse: sales_reporting
      â””â”€â”€ 99_Notebooks
          â”œâ”€â”€ Notebook: ingest_sales
          â”œâ”€â”€ Notebook: transform_sales
          â””â”€â”€ Notebook: report_generation
      
      Summary:
        Folders: 4
        Lakehouses: 3
        Warehouses: 1
        Notebooks: 3
        Pipelines: 2
        Semantic Models: 1
      
      Git Status: Connected (main branch)
    checkpoint_question: Does your workspace appear in the Fabric portal with all expected items?
    tips:
      - Bookmark the workspace URL for quick access
      - Use the utility script to verify in CI/CD pipelines

  - id: deploy-environments
    title: "Step 5: Deploy to Multiple Environments"
    type: command
    content: |
      The same configuration can deploy to different environments (dev, staging, prod).
      
      ## Environment Differences
      
      | Environment | Typical Configuration |
      |-------------|----------------------|
      | **dev** | F8 capacity, all team members as Admin |
      | **staging** | F16 capacity, limited admins, QA team access |
      | **prod** | F64 capacity, strict access control, change approval |
      
      ## How It Works
      
      - "Workspace name includes environment: `acme-sales-analytics-dev`, `-staging`, `-prod`"
      - Environment overrides in config apply different capacities, principals
      - Each environment is a separate workspace
    code:
      language: bash
      content: |
        # Deploy to development
        make deploy config=config/projects/acme_corp/sales_analytics.yaml env=dev
        
        # Deploy to staging
        make deploy config=config/projects/acme_corp/sales_analytics.yaml env=staging
        
        # Deploy to production
        make deploy config=config/projects/acme_corp/sales_analytics.yaml env=prod
        
        # List all your workspaces
        python scripts/admin/utilities/list_workspaces.py
    expected_output: |
      # After all deployments, list_workspaces.py shows:
      Found 3 workspaces:
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Workspace ID                          â”‚ Workspace Name              â”‚ Capacity â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
      â”‚ 11111111-1111-1111-1111-111111111111 â”‚ acme-sales-analytics-dev    â”‚ F8       â”‚
      â”‚ 22222222-2222-2222-2222-222222222222 â”‚ acme-sales-analytics-stagingâ”‚ F16      â”‚
      â”‚ 33333333-3333-3333-3333-333333333333 â”‚ acme-sales-analytics-prod   â”‚ F64      â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    tips:
      - "Create environment-specific overrides in `config/environments/` or inline in YAML"
      - Production deployments should go through CI/CD with approval gates

  - id: destroy-workspace
    title: "Step 6: Destroy Workspace (Cleanup)"
    type: command
    content: |
      Remove a workspace when it's no longer needed (e.g., feature branch cleanup, 
      decommissioned project).
      
      **âš ï¸ WARNING:** This permanently deletes the workspace AND all its contents!
      
      ## Destroy Options
      
      | Option | Description |
      |--------|-------------|
      | Default | Requires "yes" confirmation |
      | `--force` | Skip confirmation (for automation) |
    code:
      language: bash
      content: |
        # Destroy using Make (requires confirmation)
        make destroy config=config/projects/acme_corp/sales_analytics.yaml env=dev
        
        # Destroy using CLI (requires confirmation)
        fabric-cicd destroy config/projects/acme_corp/sales_analytics.yaml --env dev
        
        # Force destroy (skip confirmation - for automation)
        fabric-cicd destroy config/projects/acme_corp/sales_analytics.yaml --env dev --force
        
        # Bulk destroy multiple workspaces from a file
        make bulk-destroy file=workspaces_to_delete.txt
    expected_output: |
      â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
      â•‘              âš ï¸  WORKSPACE DESTRUCTION                       â•‘
      â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      
      Workspace: acme-sales-analytics-dev
      
      This will permanently delete:
        - 4 Folders
        - 3 Lakehouses (including all data!)
        - 1 Warehouse
        - 3 Notebooks
        - 2 Pipelines
        - 1 Semantic Model
      
      âš ï¸  THIS ACTION CANNOT BE UNDONE
      
      Type 'yes' to confirm: yes
      
      Destroying workspace...
      âœ“ Items deleted
      âœ“ Workspace 'acme-sales-analytics-dev' deleted
      âœ“ Logged to audit_logs/fabric_operations_2025-01-15.jsonl
      
      Destruction completed.
    warnings:
      - This action **CANNOT** be undone
      - All data in lakehouses and warehouses will be **permanently lost**
      - Use with extreme caution in production environments
      - Consider backups before destroying production workspaces
    tips:
      - "Use `--force` only in automated pipelines with proper safeguards"
      - Review the workspace in portal before confirming deletion

  - id: audit-logs
    title: "Step 7: Review Audit Logs"
    type: info
    content: |
      All deployment operations are logged in JSONL format for compliance and debugging.
      
      ## Log Location
      
      `audit_logs/fabric_operations_YYYY-MM-DD.jsonl`
      
      ## Log Entry Fields
      
      | Field | Description |
      |-------|-------------|
      | `timestamp` | ISO 8601 timestamp |
      | `operation` | create, update, delete, skip |
      | `resource_type` | workspace, lakehouse, notebook, etc. |
      | `resource_name` | Item name |
      | `workspace_name` | Parent workspace |
      | `status` | success, failure, skipped |
      | `duration_ms` | Operation duration in milliseconds |
      | `error_message` | Error details (if status=failure) |
    code:
      language: bash
      content: |
        # View today's audit logs (formatted with jq)
        cat audit_logs/fabric_operations_$(date +%Y-%m-%d).jsonl | jq '.'
        
        # Filter for failures only
        cat audit_logs/*.jsonl | jq 'select(.status == "failure")'
        
        # Filter for specific workspace
        cat audit_logs/*.jsonl | jq 'select(.workspace_name | contains("sales"))'
        
        # Count operations by type
        cat audit_logs/*.jsonl | jq -r '.operation' | sort | uniq -c
        
        # View most recent entries
        tail -n 20 audit_logs/fabric_operations_$(date +%Y-%m-%d).jsonl | jq '.'
    expected_output: |
      # Single audit log entry:
      {
        "timestamp": "2025-01-15T10:30:45.123Z",
        "operation": "create",
        "resource_type": "lakehouse",
        "resource_name": "sales_raw",
        "workspace_name": "acme-sales-analytics-dev",
        "workspace_id": "12345678-1234-1234-1234-123456789abc",
        "status": "success",
        "duration_ms": 2340,
        "config_file": "config/projects/acme_corp/sales_analytics.yaml",
        "environment": "dev"
      }
    tips:
      - Audit logs are essential for compliance (SOC2, HIPAA, etc.)
      - Consider forwarding logs to Azure Monitor, Splunk, or similar
      - Logs rotate daily - implement retention policy for long-term storage

  - id: next-steps
    title: "ğŸ‰ Deployment Complete - Next Steps"
    type: info
    content: |
      You've successfully deployed a Fabric workspace from your local machine!
      
      ## What You've Accomplished
      
      - âœ… Activated the correct conda environment
      - âœ… Validated configuration before deployment
      - "âœ… Deployed workspace with `make deploy`"
      - âœ… Understand idempotent deployment behavior
      - âœ… Verified deployment with utility scripts
      - âœ… Know how to destroy workspaces safely
      - âœ… Can review audit logs for compliance
      
      ## Quick Command Reference
      
      | Task | Command |
      |------|---------|
      | Validate | `make validate config=<path>` |
      | Deploy | `make deploy config=<path> env=<env>` |
      | Validate Only | `fabric-cicd deploy <path> --env <env> --validate-only` |
      | Verify | `python scripts/admin/utilities/list_workspace_items.py --workspace <name>` |
      | Destroy | `make destroy config=<path> env=<env>` |
      | View Logs | `cat audit_logs/fabric_operations_$(date +%Y-%m-%d).jsonl \| jq` |
      
      ## Recommended Next Steps
      
      1. **Next:** [Docker Deployment](#docker-deployment) - CI/CD pipeline integration
      2. **Then:** [Feature Branch Workflows](#feature-branch-workflows) - Isolated development
      3. **Advanced:** [Git Integration](#git-integration) - Version control connection
    code:
      language: bash
      content: |
        # Complete workflow summary:
        
        # 1. Generate config
        python scripts/dev/generate_project.py "My Company" "My Project" --template basic_etl
        
        # 2. Validate
        make validate config=config/projects/my_company/my_project.yaml
        
        # 3. Deploy
        make deploy config=config/projects/my_company/my_project.yaml env=dev
        
        # 4. Verify
        python scripts/admin/utilities/list_workspace_items.py --workspace "my-company-my-project-dev"
    tips:
      - Master local deployment before moving to Docker
      - Use local deployment for development and testing
      - Use Docker deployment for CI/CD pipelines
