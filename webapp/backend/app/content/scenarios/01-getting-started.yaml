# Getting Started Scenario
# Comprehensive setup guide with exact terminal commands and expected outputs

id: getting-started
title: Getting Started with Fabric CLI CI/CD
description: |
  Complete step-by-step setup guide for the Fabric CLI CI/CD framework. Learn to install the conda 
  environment, configure Service Principal credentials, verify your setup with preflight checks, 
  and understand all available commands (Make targets, CLI entry points, and Python scripts).
difficulty: beginner
estimated_duration_minutes: 30
category: getting-started
order: 1

prerequisites: []

learning_outcomes:
  - "Install and configure the conda environment with `conda env create` and `make install`"
  - Understand all available entry points (Make, CLI, Python scripts)
  - "Configure Azure Service Principal credentials in `.env` file"
  - "Run `make diagnose` and `python scripts/admin/preflight_check.py` to verify setup"
  - "Use `python scripts/admin/utilities/list_workspaces.py` to confirm API connectivity"
  - Know when to use Make vs CLI vs Python script commands

tags:
  - installation
  - setup
  - prerequisites
  - conda
  - environment
  - credentials
  - service-principal
  - makefile
  - cli

related_scenarios:
  - project-generation
  - local-deployment

steps:
  - id: overview
    title: What is Fabric CLI CI/CD?
    type: info
    content: |
      The **Fabric CLI CI/CD Framework** is an enterprise-grade Microsoft Fabric deployment automation tool.
      It follows a **thin wrapper architecture** where 90% of work is delegated to the official Microsoft 
      Fabric CLI, with only ~270 lines of orchestration code.
      
      ## Key Capabilities
      
      | Feature | Description |
      |---------|-------------|
      | **Workspace Deployment** | Create workspaces, lakehouses, notebooks, pipelines, semantic models |
      | **Blueprint Templates** | 10 production-ready templates (basic_etl, realtime_streaming, compliance_regulated, etc.) |
      | **Git Integration** | Connect workspaces to Azure DevOps or GitHub repos |
      | **Feature Branch Isolation** | Create isolated workspaces per feature branch |
      | **Docker Support** | Containerized deployments for CI/CD pipelines |
      | **Audit Logging** | JSONL compliance logs in `audit_logs/` directory |
      
      ## Three Ways to Use the Framework
      
      | Method | When to Use | Example |
      |--------|-------------|---------|
      | **Make Commands** | Recommended - simple, discoverable | `make deploy config=path.yaml env=dev` |
      | **CLI Entry Point** | Direct CLI access after `pip install -e .` | `fabric-cicd deploy path.yaml --env dev` |
      | **Python Scripts** | Utilities and advanced operations | `python scripts/dev/generate_project.py "Org" "Proj"` |
      
      This guide walks you through setting up all three methods.
    tips:
      - "Start with Make commands - run `make help` to see all options"
      - "The CLI entry point `fabric-cicd` becomes available after running `make install`"

  - id: prerequisites-check
    title: "Step 1: Check Prerequisites"
    type: checkpoint
    content: |
      Before proceeding, verify you have the required software installed.
      
      ## Required Software
      
      | Tool | Minimum Version | Check Command |
      |------|-----------------|---------------|
      | Python | 3.11+ | `python --version` |
      | Conda | Any | `conda --version` |
      | Git | Any | `git --version` |
      | Docker | 20+ (optional) | `docker --version` |
      
      ## Azure Requirements
      
      | Requirement | How to Get It |
      |-------------|---------------|
      | **Service Principal** | Azure Portal â†’ App registrations â†’ New registration |
      | **Fabric Capacity** | Azure Portal â†’ Create resource â†’ Fabric Capacity (F2 minimum) |
      | **Tenant Admin Grant** | Admin Portal â†’ Tenant settings â†’ Enable "Service principals can use Fabric APIs" |
      
      Run these commands to verify your local prerequisites:
    code:
      language: bash
      content: |
        # Check Python version (should be 3.11+)
        python --version
        
        # Check Conda is installed
        conda --version
        
        # Check Git is installed
        git --version
        
        # Check Docker (optional - for containerized deployments)
        docker --version
    expected_output: |
      Python 3.11.9
      conda 24.5.0
      git version 2.43.0
      Docker version 24.0.7, build afdd53b (optional)
    checkpoint_question: Do you have Python 3.11+, Conda, and Git installed?
    warnings:
      - "If Python version is below 3.11, install via `conda install python=3.11`"
      - "Docker is optional but required for `make docker-*` commands"

  - id: azure-prerequisites
    title: "Step 2: Azure Prerequisites (CRITICAL)"
    type: info
    content: |
      **âš ï¸ STOP HERE if you don't have Azure access!** This step requires Azure Portal access and 
      potentially Fabric Admin permissions. Work with your Azure/Fabric administrator if needed.
      
      ## What You Need (Checklist)
      
      | âœ“ | Requirement | Who Can Create It |
      |---|-------------|-------------------|
      | â˜ | **Azure Service Principal** | Any Azure AD user with App registration permission |
      | â˜ | **Client Secret for SP** | Owner of the Service Principal |
      | â˜ | **Fabric Capacity (F2+)** | Azure Subscription Owner or Contributor |
      | â˜ | **Fabric Tenant Settings** | Fabric Admin only |
      
      ## Step 2a: Create Service Principal
      
      1. Go to **Azure Portal** â†’ **Microsoft Entra ID** â†’ **App registrations**
      2. Click **+ New registration**
      3. Enter name: `fabric-cli-cicd-sp` (or your preferred name)
      4. Select: **Accounts in this organizational directory only**
      5. Click **Register**
      6. **Copy and save** the **Application (client) ID** â†’ This is your `AZURE_CLIENT_ID`
      7. **Copy and save** the **Directory (tenant) ID** â†’ This is your `AZURE_TENANT_ID`
      
      ## Step 2b: Create Client Secret
      
      1. In your new App registration, go to **Certificates & secrets**
      2. Click **+ New client secret**
      3. Add description: `fabric-cli-cicd-secret`
      4. Set expiration: **12 months** (or per your security policy)
      5. Click **Add**
      6. **IMMEDIATELY copy the Value** â†’ This is your `AZURE_CLIENT_SECRET`
      
      âš ï¸ **WARNING:** The secret value is only shown ONCE! Copy it immediately.
      
      ## Step 2c: Get or Create Fabric Capacity
      
      **Option A: Use existing capacity**
      1. Go to **Fabric Admin Portal** â†’ **Capacity settings**
      2. Select your capacity
      3. Copy the **Capacity ID** from the URL (GUID format)
      
      **Option B: Create new capacity (if you have Azure Subscription access)**
      1. Go to **Azure Portal** â†’ **Create a resource**
      2. Search for **Microsoft Fabric**
      3. Select **Microsoft Fabric Capacity**
      4. Choose **F2** (smallest, good for dev/test)
      5. Complete creation, then get the Capacity ID
      
      ## Step 2d: Enable Fabric Tenant Settings (Requires Fabric Admin)
      
      1. Go to **Fabric Admin Portal** (admin.powerbi.com)
      2. Navigate to **Tenant settings**
      3. Enable these settings for your Service Principal or security group:
      
      | Setting | Location | Required |
      |---------|----------|----------|
      | Service principals can use Fabric APIs | Developer settings | âœ… Yes |
      | Service principals can create and use profiles | Developer settings | âœ… Yes |
      | Users can create Fabric items | Workspace settings | âœ… Yes |
      
      ## Summary: What You Should Have Now
      
      | Credential | Example Format | Where to Put It |
      |------------|----------------|-----------------|
      | `AZURE_CLIENT_ID` | `12345678-1234-1234-1234-123456789abc` | `.env` file |
      | `AZURE_CLIENT_SECRET` | `abc123~secret~value` | `.env` file |
      | `AZURE_TENANT_ID` | `87654321-4321-4321-4321-cba987654321` | `.env` file |
      | `FABRIC_CAPACITY_ID` | `abcd1234-abcd-1234-abcd-1234567890ab` | `.env` file |
    warnings:
      - "ğŸ”´ DO NOT proceed without these 4 credentials - deployment will fail!"
      - "Client Secret is shown only ONCE - copy it immediately after creation"
      - "Fabric tenant settings require Fabric Admin access - contact your admin"
    tips:
      - Create a dedicated Service Principal for CI/CD (don't use personal credentials)
      - "Use a security group to manage tenant settings: add the SP to the group"
      - F2 capacity is sufficient for development and testing

  - id: clone-repository
    title: "Step 3: Clone the Repository"
    type: command
    content: |
      Clone the repository to your local machine. Choose a location where you'll work with the project.
      
      **If you already have the repository**, skip to the next step.
    code:
      language: bash
      content: |
        # Navigate to your projects directory
        cd ~/projects
        
        # Clone the repository (replace with your actual URL)
        git clone https://github.com/your-org/usf_fabric_cli_cicd.git
        
        # Or clone via SSH
        git clone git@github.com:your-org/usf_fabric_cli_cicd.git
        
        # Navigate into the project
        cd usf_fabric_cli_cicd
        
        # Verify you're in the right place
        ls -la
    expected_output: |
      total 88
      drwxrwxr-x 12 user user  4096 Jan 15 10:00 .
      drwxrwxr-x  8 user user  4096 Jan 15 09:55 ..
      -rw-rw-r--  1 user user  1234 Jan 15 10:00 Makefile
      -rw-rw-r--  1 user user  5678 Jan 15 10:00 README.md
      -rw-rw-r--  1 user user   890 Jan 15 10:00 environment.yml
      -rw-rw-r--  1 user user  2345 Jan 15 10:00 pyproject.toml
      drwxrwxr-x  3 user user  4096 Jan 15 10:00 config
      drwxrwxr-x  3 user user  4096 Jan 15 10:00 scripts
      drwxrwxr-x  4 user user  4096 Jan 15 10:00 src
      drwxrwxr-x  3 user user  4096 Jan 15 10:00 templates
    tips:
      - "The `Makefile` contains all available Make commands"
      - "The `scripts/` directory contains Python utility scripts"
      - "The `templates/blueprints/` directory contains the 10 blueprint templates"

  - id: create-environment
    title: "Step 4: Create Conda Environment"
    type: command
    content: |
      The project uses a conda environment defined in `environment.yml`. This ensures consistent 
      Python versions and dependencies across all team members.
      
      ## Why Conda?
      
      - "**Isolation**: Keeps project dependencies separate from system Python"
      - "**Reproducibility**: Same package versions for all developers"
      - "**Cross-platform**: Works on Windows, macOS, and Linux"
      
      Create and activate the environment:
    code:
      language: bash
      content: |
        # Create the conda environment from environment.yml
        conda env create -f environment.yml
        
        # Activate the environment
        conda activate fabric-cli-cicd
        
        # Verify you're in the correct environment
        conda env list
    expected_output: |
      Solving environment: done
      Preparing transaction: done
      Verifying transaction: done
      Executing transaction: done
      
      # After activation:
      # conda environments:
      #
      base                     /home/user/miniconda3
      fabric-cli-cicd       *  /home/user/miniconda3/envs/fabric-cli-cicd
    tips:
      - The asterisk (*) indicates the active environment
      - "**ALWAYS** activate this environment before running any commands"
      - "Add `conda activate fabric-cli-cicd` to your shell startup script"
    warnings:
      - "Running commands without activating the environment causes `ModuleNotFoundError`"
      - "If you see import errors, first check `conda env list` to verify the environment"

  - id: install-package
    title: "Step 5: Install Package and CLI Entry Point"
    type: command
    content: |
      Install the package in editable mode to enable the `fabric-cicd` CLI command 
      and allow live code changes during development.
      
      ## What Gets Installed
      
      | Component | Description |
      |-----------|-------------|
      | `fabric-cicd` command | Main CLI entry point (defined in `pyproject.toml`) |
      | `src/usf_fabric_cli/` modules | Core Python libraries |
      | Dependencies | typer, rich, pyyaml, jinja2, python-dotenv, azure-identity |
      
      ## Installation Methods
      
      You have two options:
    code:
      language: bash
      content: |
        # Option 1: Use Makefile (RECOMMENDED)
        make install
        
        # Option 2: Use pip directly
        pip install -e .
        
        # Verify the CLI is available
        fabric-cicd --help
    expected_output: |
      # After make install:
      Successfully installed usf-fabric-cli-1.3.0
      
      # After fabric-cicd --help:
      Usage: fabric-cicd [OPTIONS] COMMAND [ARGS]...
      
        Fabric CLI CI/CD - Enterprise Deployment Framework
      
      Options:
        --version  Show version
        --help     Show this message and exit.
      
      Commands:
        deploy    Deploy Fabric workspace from configuration file.
        destroy   Destroy Fabric workspace and all items.
        diagnose  Run preflight diagnostics.
        validate  Validate configuration file syntax and structure.
    tips:
      - "The `-e` flag installs in \"editable\" mode - code changes take effect immediately"
      - "If `fabric-cicd` isn't found, ensure conda environment is active"
      - "Alternative: use `python -m usf_fabric_cli.cli` instead of `fabric-cicd`"

  - id: makefile-commands
    title: "Step 6: Understand Available Make Commands"
    type: info
    content: |
      The `Makefile` provides the simplest way to interact with the framework.
      Run `make help` to see all available commands.
      
      ## Local Operations
      
      | Command | Description | Example |
      |---------|-------------|---------|
      | `make help` | Show all commands | `make help` |
      | `make install` | Install package | `make install` |
      | `make diagnose` | Run preflight check | `make diagnose` |
      | `make validate` | Validate config | `make validate config=path/to/config.yaml` |
      | `make deploy` | Deploy workspace | `make deploy config=path/to/config.yaml env=dev` |
      | `make destroy` | Destroy workspace | `make destroy config=path/to/config.yaml env=dev` |
      | `make bulk-destroy` | Bulk destroy | `make bulk-destroy file=workspaces.txt` |
      
      ## Docker Operations
      
      | Command | Description |
      |---------|-------------|
      | `make docker-build` | Build Docker image |
      | `make docker-shell ENVFILE=.env` | Interactive container shell |
      | `make docker-diagnose ENVFILE=.env` | Preflight check in container |
      | `make docker-validate config=... ENVFILE=.env` | Validate in container |
      | `make docker-deploy config=... env=dev ENVFILE=.env` | Deploy from container |
      | `make docker-destroy config=... ENVFILE=.env` | Destroy from container |
      | `make docker-generate org="Org" project="Proj" template="basic_etl"` | Generate config |
      | `make docker-init-repo org="ADOOrg" project="ADOProj" repo="RepoName"` | Init ADO repo |
      | `make docker-feature-deploy config=... env=dev branch=feature/x` | Feature branch deploy |
      
      ## Development Commands
      
      | Command | Description |
      |---------|-------------|
      | `make test` | Run unit tests |
      | `make test-integration` | Run integration tests |
      | `make lint` | Run linters |
      | `make build` | Build wheel package |
      | `make clean` | Clean build artifacts |
    code:
      language: bash
      content: |
        # See all available commands with descriptions
        make help
        
        # Run preflight diagnostics
        make diagnose
        
        # Validate a sample template
        make validate config=templates/blueprints/basic_etl.yaml
    expected_output: |
      # make help output:
      Available targets:
        help              Show this help message
        install           Install dependencies in editable mode
        test              Run unit tests
        test-integration  Run integration tests
        lint              Run code linters
        build             Build distribution package
        clean             Clean build artifacts
        diagnose          Run preflight diagnostic check
        validate          Validate configuration file
        deploy            Deploy workspace from configuration
        destroy           Destroy workspace
        bulk-destroy      Bulk destroy workspaces from file
        docker-build      Build Docker image
        docker-shell      Start interactive shell in container
        docker-diagnose   Run preflight check in container
        docker-deploy     Deploy from Docker container
        docker-destroy    Destroy from Docker container
        docker-validate   Validate config in container
        docker-generate   Generate project config in container
        docker-init-repo  Initialize ADO repository
        docker-feature-deploy  Deploy feature branch workspace
    tips:
      - Make commands are the recommended way to use the framework
      - They handle environment activation and parameter passing
      - "All Docker commands require `ENVFILE=.env` to pass credentials"

  - id: cli-commands
    title: "Step 7: Understand CLI Entry Points"
    type: info
    content: |
      After `make install`, the `fabric-cicd` CLI command becomes available.
      This provides a more direct interface than Make commands.
      
      ## CLI Commands Reference
      
      ### fabric-cicd deploy
      ```bash
      fabric-cicd deploy <config_path> --env <environment> [options]
      ```
      
      | Option | Description |
      |--------|-------------|
      | `--env`, `-e` | Target environment (dev, staging, prod) |
      | `--branch`, `-b` | Feature branch name |
      | `--force-branch-workspace` | Force create branch workspace |
      | `--diagnose` | Show diagnostic output |
      | `--validate-only` | Validate config without deploying |
      
      ### fabric-cicd validate
      ```bash
      fabric-cicd validate <config_path> [--env <environment>]
      ```
      
      ### fabric-cicd destroy
      ```bash
      fabric-cicd destroy <config_path> [--env <environment>] [--force]
      ```
      
      ### fabric-cicd diagnose
      ```bash
      fabric-cicd diagnose
      ```
    code:
      language: bash
      content: |
        # Deploy to development environment
        fabric-cicd deploy config/projects/acme/sales.yaml --env dev
        
        # Deploy with feature branch isolation
        fabric-cicd deploy config/projects/acme/sales.yaml --env dev --branch feature/new-pipeline
        
        # Validate configuration
        fabric-cicd validate config/projects/acme/sales.yaml
        
        # Validate only (no deployment)
        fabric-cicd deploy config/projects/acme/sales.yaml --env dev --validate-only
        
        # Destroy workspace (with confirmation)
        fabric-cicd destroy config/projects/acme/sales.yaml --env dev
        
        # Force destroy (skip confirmation)
        fabric-cicd destroy config/projects/acme/sales.yaml --env dev --force
        
        # Run diagnostics
        fabric-cicd diagnose
        
        # Alternative: Use Python module syntax
        python -m usf_fabric_cli.cli deploy config/projects/acme/sales.yaml --env dev
    tips:
      - "Use `--validate-only` to check config without deploying"
      - "Use `--diagnose` for verbose output during troubleshooting"
      - "`python -m usf_fabric_cli.cli` works even if the entry point isn't registered"

  - id: python-scripts
    title: "Step 8: Understand Python Utility Scripts"
    type: info
    content: |
      The `scripts/` directory contains Python utilities for advanced operations
      not covered by Make commands or CLI.
      
      ## Main Scripts
      
      | Script | Purpose | Example |
      |--------|---------|---------|
      | `generate_project.py` | Create config from template | `python scripts/dev/generate_project.py "Org" "Project" --template basic_etl` |
      | `preflight_check.py` | Validate environment | `python scripts/admin/preflight_check.py --auto-install` |
      | `bulk_destroy.py` | Destroy multiple workspaces | `python scripts/admin/bulk_destroy.py workspaces.txt` |
      
      ## Utility Scripts (in `scripts/admin/utilities/`)
      
      | Script | Purpose |
      |--------|---------|
      | `list_workspaces.py` | List all accessible workspaces |
      | `list_workspace_items.py` | List items in a workspace |
      | `init_ado_repo.py` | Initialize Azure DevOps repository |
      | `debug_ado_access.py` | Debug ADO permission issues |
      | `debug_connection.py` | Debug connectivity issues |
      | `analyze_migration.py` | Analyze workspace for migration |
    code:
      language: bash
      content: |
        # Generate a new project configuration
        python scripts/dev/generate_project.py "Acme Corp" "Sales Analytics" \
          --template basic_etl \
          --git-repo "https://dev.azure.com/acme/FabricProjects/_git/sales"
        # Output: config/projects/acme_corp/sales_analytics.yaml
        
        # Run preflight check
        python scripts/admin/preflight_check.py
        
        # Run preflight check with auto-install
        python scripts/admin/preflight_check.py --auto-install
        
        # List your accessible workspaces
        python scripts/admin/utilities/list_workspaces.py
        
        # List items in a specific workspace
        python scripts/admin/utilities/list_workspace_items.py --workspace "my-workspace-name"
        
        # Initialize Azure DevOps repository
        python scripts/admin/utilities/init_ado_repo.py \
          --organization "your-ado-org" \
          --project "FabricProjects" \
          --repository "new-repo-name"
        
        # Debug ADO access issues
        python scripts/admin/utilities/debug_ado_access.py \
          --organization "your-ado-org" \
          --project "FabricProjects"
    tips:
      - "Always run `conda activate fabric-cli-cicd` before running Python scripts"
      - "Use `python scripts/dev/generate_project.py --help` to see all template options"
      - The utility scripts are invaluable for debugging permission issues

  - id: configure-credentials
    title: "Step 9: Configure Credentials (.env File)"
    type: config
    content: |
      The framework uses the **12-Factor App** pattern for credential management.
      
      ## Credential Waterfall Priority
      
      | Priority | Source | Use Case |
      |----------|--------|----------|
      | 1 (Highest) | Environment Variables | CI/CD pipelines |
      | 2 | `.env` file | Local development |
      | 3 | Azure Key Vault | Enterprise production |
      
      ## Required Environment Variables
      
      | Variable | Required | Description |
      |----------|----------|-------------|
      | `AZURE_CLIENT_ID` | âœ… Yes | Service Principal Application (Client) ID |
      | `AZURE_CLIENT_SECRET` | âœ… Yes | Service Principal Secret Value |
      | `AZURE_TENANT_ID` | âœ… Yes | Azure AD Tenant ID |
      | `FABRIC_CAPACITY_ID` | âœ… Yes | Fabric Capacity GUID |
      
      ## Optional Variables
      
      | Variable | Purpose |
      |----------|---------|
      | `GIT_REPO_URL` | Default Git repository URL |
      | `AZURE_DEVOPS_PAT` | Azure DevOps Personal Access Token |
      | `GITHUB_TOKEN` | GitHub Personal Access Token |
      | `DEV_ADMIN_OBJECT_ID` | Object ID for workspace admin principal |
      | `DEV_CONTRIBUTOR_OBJECT_ID` | Object ID for workspace contributor principal |
      
      Create your `.env` file from the template:
    code:
      language: bash
      content: |
        # Copy the template
        cp .env.template .env
        
        # Edit with your values
        nano .env
        # OR: vim .env
        # OR: code .env  (VS Code)
    tips:
      - "Never commit `.env` files to version control - they're in `.gitignore`"
      - Use Azure Key Vault for production environments
      - Rotate secrets regularly
    warnings:
      - âš ï¸ NEVER hardcode credentials in code or YAML files
      - "âš ï¸ NEVER commit `.env` files to Git"

  - id: env-file-content
    title: "Step 10: Configure .env File Contents"
    type: config
    content: |
      Here's a complete example `.env` file with all variables explained.
      
      ## Getting Your Credentials
      
      | Variable | Where to Find It |
      |----------|-----------------|
      | `AZURE_CLIENT_ID` | Azure Portal â†’ App registrations â†’ Your SP â†’ Application (client) ID |
      | `AZURE_CLIENT_SECRET` | Azure Portal â†’ App registrations â†’ Your SP â†’ Certificates & secrets â†’ New client secret |
      | `AZURE_TENANT_ID` | Azure Portal â†’ Microsoft Entra ID â†’ Overview â†’ Tenant ID |
      | `FABRIC_CAPACITY_ID` | Fabric Admin Portal â†’ Capacity settings â†’ Select capacity â†’ Copy GUID from URL |
      | `AZURE_DEVOPS_PAT` | Azure DevOps â†’ User settings â†’ Personal access tokens â†’ New Token |
    code:
      language: dotenv
      filename: .env
      content: |
        # ============================================
        # Azure Service Principal Credentials
        # Get these from Azure Portal â†’ App registrations
        # ============================================
        AZURE_CLIENT_ID=12345678-1234-1234-1234-123456789abc
        AZURE_CLIENT_SECRET=your-client-secret-value-here
        AZURE_TENANT_ID=87654321-4321-4321-4321-cba987654321
        
        # ============================================
        # Microsoft Fabric Configuration
        # Get Capacity ID from Fabric Admin Portal
        # ============================================
        FABRIC_CAPACITY_ID=abcd1234-abcd-1234-abcd-1234567890ab
        
        # ============================================
        # Git Integration (Azure DevOps)
        # Only required if using Git integration
        # ============================================
        GIT_REPO_URL=https://dev.azure.com/your-org/your-project/_git/your-repo
        AZURE_DEVOPS_PAT=your-pat-token-here
        
        # ============================================
        # Git Integration (GitHub) - Alternative
        # Use instead of Azure DevOps variables
        # ============================================
        # GITHUB_TOKEN=ghp_your_github_token
        
        # ============================================
        # Workspace Principal Assignments (Optional)
        # Object IDs for users/groups to assign to workspaces
        # ============================================
        DEV_ADMIN_OBJECT_ID=11111111-1111-1111-1111-111111111111
        DEV_CONTRIBUTOR_OBJECT_ID=22222222-2222-2222-2222-222222222222
    warnings:
      - Replace all placeholder values with your actual credentials
      - "The `AZURE_CLIENT_SECRET` is shown only once in Azure - save it securely"
      - PAT tokens expire - set appropriate expiration dates

  - id: verify-env-file
    title: "Step 11: Verify Your .env File is Correct"
    type: command
    content: |
      **Before running preflight**, verify your `.env` file is syntactically correct
      and all required variables are set.
      
      ## Quick Validation Commands
      
      | Check | Command | What It Does |
      |-------|---------|--------------|
      | File exists | `ls -la .env` | Confirms .env was created |
      | Has content | `wc -l .env` | Shows line count |
      | Required vars | `grep -E "^AZURE_" .env` | Lists Azure credentials |
      | Capacity ID | `grep "FABRIC_CAPACITY_ID" .env` | Confirms capacity set |
      
      ## .env Checklist
      
      ```
      âœ“ AZURE_CLIENT_ID      - Should be a GUID (36 characters)
      âœ“ AZURE_CLIENT_SECRET  - Your SP secret (variable length)
      âœ“ AZURE_TENANT_ID      - Should be a GUID (36 characters)
      âœ“ FABRIC_CAPACITY_ID   - Should be a GUID (36 characters)
      ```
    code:
      language: bash
      content: |
        # Check the file exists and has content
        ls -la .env
        wc -l .env
        
        # Verify required variables are set (shows variable names, NOT values)
        echo "=== Checking Required Variables ==="
        grep -q "^AZURE_CLIENT_ID=" .env && echo "âœ“ AZURE_CLIENT_ID is set" || echo "âœ— AZURE_CLIENT_ID is MISSING"
        grep -q "^AZURE_CLIENT_SECRET=" .env && echo "âœ“ AZURE_CLIENT_SECRET is set" || echo "âœ— AZURE_CLIENT_SECRET is MISSING"
        grep -q "^AZURE_TENANT_ID=" .env && echo "âœ“ AZURE_TENANT_ID is set" || echo "âœ— AZURE_TENANT_ID is MISSING"
        grep -q "^FABRIC_CAPACITY_ID=" .env && echo "âœ“ FABRIC_CAPACITY_ID is set" || echo "âœ— FABRIC_CAPACITY_ID is MISSING"
        
        # Check for placeholder text that shouldn't be there
        echo ""
        echo "=== Checking for Unedited Placeholders ==="
        grep -q "your_" .env && echo "âš ï¸  WARNING: Found 'your_' placeholder - edit these values!" || echo "âœ“ No obvious placeholders found"
        grep -q "xxxx" .env && echo "âš ï¸  WARNING: Found 'xxxx' placeholder - edit these values!" || echo "âœ“ No xxxx placeholders found"
    expected_output: |
      -rw-rw-r-- 1 user user 1234 Jan 15 10:00 .env
      45 .env
      
      === Checking Required Variables ===
      âœ“ AZURE_CLIENT_ID is set
      âœ“ AZURE_CLIENT_SECRET is set
      âœ“ AZURE_TENANT_ID is set
      âœ“ FABRIC_CAPACITY_ID is set
      
      === Checking for Unedited Placeholders ===
      âœ“ No obvious placeholders found
      âœ“ No xxxx placeholders found
    tips:
      - "If any variable is MISSING, edit `.env` and add it"
      - "Use `code .env` to open in VS Code for editing"
      - "Never run `cat .env` in shared terminals - it exposes secrets"
    warnings:
      - "ğŸ”´ NEVER commit `.env` to Git - it contains secrets"
      - "ğŸ”´ NEVER share `.env` file contents in screenshots or logs"
      - "If you see 'your_' placeholders, you haven't finished editing"

  - id: generate-first-project
    title: "Step 12: Generate Your First Project Config"
    type: command
    content: |
      Project configurations are generated from **blueprint templates** using the project generator script.
      This ensures consistent structure and includes all required fields.
      
      ## Available Templates
      
      | Template | Description | Use Case |
      |----------|-------------|----------|
      | `basic_etl` | Standard ETL pipeline | Most common starting point |
      | `advanced_analytics` | Full analytics stack | BI and reporting projects |
      | `realtime_streaming` | Event-driven architecture | IoT and streaming data |
      | `compliance_regulated` | Audit-heavy configuration | Healthcare, finance |
      | `data_mesh_domain` | Domain-oriented design | Large organizations |
      | `minimal_starter` | Bare minimum config | Learning and testing |
      | `migration_hybrid` | Legacy migration support | Migrating from SSAS/AAS |
      | `specialized_timeseries` | Time-series analytics | Monitoring and metrics |
      | `extensive_example` | All features demonstrated | Reference implementation |
      
      ## Generate Your First Config
      
      The generator creates a YAML configuration file customized with your organization
      and project names. Output location: `config/projects/<org_slug>/<project_slug>.yaml`
    code:
      language: bash
      content: |
        # Generate a basic ETL project configuration
        python scripts/dev/generate_project.py "YourOrg" "YourProject" --template basic_etl
        
        # Example with real names
        python scripts/dev/generate_project.py "Acme Corp" "Sales Analytics" --template basic_etl
        # Output: config/projects/acme_corp/sales_analytics.yaml
        
        # Generate with Git repository URL
        python scripts/dev/generate_project.py "Acme Corp" "Sales Analytics" \
          --template basic_etl \
          --git-repo "https://dev.azure.com/acme/FabricProjects/_git/sales"
        
        # View all available templates and options
        python scripts/dev/generate_project.py --help
    expected_output: |
      â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
      â•‘              Fabric CLI Project Generator                    â•‘
      â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      
      Organization: Acme Corp
      Project: Sales Analytics
      Template: basic_etl
      
      âœ“ Created directory: config/projects/acme_corp
      âœ“ Generated configuration: config/projects/acme_corp/sales_analytics.yaml
      
      Next steps:
        1. Review and customize the generated file
        2. Update environment-specific values (capacity, principals)
        3. Run: make validate config=config/projects/acme_corp/sales_analytics.yaml
        4. Deploy: make deploy config=config/projects/acme_corp/sales_analytics.yaml env=dev
    tips:
      - "Start with `minimal_starter` template for learning"
      - "Use `basic_etl` for most production projects"
      - "Run `python scripts/dev/generate_project.py --help` to see all options"
      - Customize the generated YAML file to match your specific requirements
    warnings:
      - Remember to update placeholder values in the generated file
      - Review the `principals` section to set correct access permissions

  - id: preflight-check
    title: "Step 13: Run Preflight Check"
    type: command
    content: |
      The preflight check validates your entire setup:
      
      | Check | What It Validates |
      |-------|-------------------|
      | Fabric CLI | Installation and version |
      | Credentials | `.env` file and required variables |
      | Token Generation | Can authenticate with Service Principal |
      | API Access | Can connect to Fabric REST API |
      | Capacity | Can access the specified Fabric capacity |
      
      Run the preflight check to verify everything is configured correctly:
    code:
      language: bash
      content: |
        # Run preflight check using Make (recommended)
        make diagnose
        
        # OR run the Python script directly
        python scripts/admin/preflight_check.py
        
        # OR with auto-install option (installs Fabric CLI if missing)
        python scripts/admin/preflight_check.py --auto-install
        
        # OR using the CLI
        fabric-cicd diagnose
    expected_output: |
      â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
      â•‘            Fabric CLI CI/CD Preflight Check                  â•‘
      â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      
      Checking Fabric CLI...
      âœ“ Fabric CLI installed (version 0.1.5)
      
      Checking Credentials...
      âœ“ .env file found
      âœ“ AZURE_CLIENT_ID loaded
      âœ“ AZURE_CLIENT_SECRET loaded
      âœ“ AZURE_TENANT_ID loaded
      âœ“ FABRIC_CAPACITY_ID loaded
      
      Checking Authentication...
      âœ“ Token generation successful
      
      Checking Fabric API...
      âœ“ Fabric API accessible
      âœ“ Capacity access verified
      
      â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
      âœ… All preflight checks passed!
      â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    tips:
      - Run this check whenever you change credentials
      - Run this check before your first deployment
      - Run this check when troubleshooting failures
    warnings:
      - If any check fails, see the Troubleshooting scenario for solutions

  - id: verify-api-access
    title: "Step 14: Verify API Access"
    type: command
    content: |
      After preflight passes, verify you can actually interact with the Fabric API
      by listing your accessible workspaces.
      
      This confirms:
      - Service Principal credentials are valid
      - Service Principal has necessary Fabric permissions
      - Network connectivity to Fabric API is working
    code:
      language: bash
      content: |
        # List all workspaces accessible to your Service Principal
        python scripts/admin/utilities/list_workspaces.py
        
        # You should see a list of workspaces (may be empty if none exist yet)
    expected_output: |
      Authenticating with Service Principal...
      âœ“ Authenticated successfully
      
      Fetching workspaces...
      
      Found 3 workspaces:
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚ Workspace ID                          â”‚ Workspace Name        â”‚ Type         â”‚
      â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
      â”‚ 11111111-1111-1111-1111-111111111111 â”‚ Sales-Analytics-Dev   â”‚ Workspace    â”‚
      â”‚ 22222222-2222-2222-2222-222222222222 â”‚ Sales-Analytics-Prod  â”‚ Workspace    â”‚
      â”‚ 33333333-3333-3333-3333-333333333333 â”‚ Marketing-Reports     â”‚ Workspace    â”‚
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    tips:
      - If no workspaces appear, that's OK for a new setup
      - The important thing is that the API call succeeds without errors
      - If you get an empty list, you can proceed to create your first workspace

  - id: service-principal-setup
    title: "Service Principal Permissions Reference"
    type: info
    content: |
      For the framework to work correctly, your Service Principal needs specific permissions.
      
      ## Fabric Tenant Settings (Admin Portal)
      
      Navigate to: **Fabric Admin Portal** â†’ **Tenant settings**
      
      | Setting | Status | Location |
      |---------|--------|----------|
      | "Service principals can use Fabric APIs" | âœ… Enabled | Developer settings |
      | "Service principals can create workspaces" | âœ… Enabled | Workspace settings |
      | "Service principals can use Git integration" | âœ… Enabled | Git integration (if using) |
      
      ## Azure DevOps Permissions (for Git Integration)
      
      | Permission | Level | How to Set |
      |------------|-------|------------|
      | **Basic** access level | Organization | Organization Settings â†’ Users â†’ Add user â†’ Access level: Basic |
      | **Contributor** role | Project | Project Settings â†’ Teams â†’ Add member â†’ Role: Contributor |
      | **Contribute** permission | Repository | Project Settings â†’ Repositories â†’ Security â†’ Add user |
      
      ## Fabric Workspace Permissions
      
      When deploying, the Service Principal needs **Admin** role on target workspaces.
      This is configured automatically via the `principals` section in your YAML config.
    warnings:
      - Most deployment failures are caused by missing SP permissions
      - Stakeholder access in ADO is NOT sufficient - must be Basic
      - Check permissions BEFORE troubleshooting other issues

  - id: next-steps
    title: "ğŸ‰ Setup Complete - Next Steps"
    type: info
    content: |
      **Congratulations!** Your Fabric CLI CI/CD environment is fully configured.
      
      ## What You've Accomplished
      
      - âœ… Created and activated the conda environment
      - "âœ… Installed the package with `make install`"
      - âœ… Learned all three command methods (Make, CLI, Scripts)
      - "âœ… Configured Service Principal credentials in `.env`"
      - âœ… Verified setup with preflight checks
      - âœ… Confirmed Fabric API connectivity
      
      ## Command Quick Reference Card
      
      | Task | Make Command | CLI Command | Script |
      |------|--------------|-------------|--------|
      | **Diagnose** | `make diagnose` | `fabric-cicd diagnose` | `python scripts/admin/preflight_check.py` |
      | **Generate Project** | - | - | `python scripts/dev/generate_project.py "Org" "Proj" --template basic_etl` |
      | **Validate Config** | `make validate config=...` | `fabric-cicd validate ...` | - |
      | **Deploy** | `make deploy config=... env=dev` | `fabric-cicd deploy ... --env dev` | - |
      | **Destroy** | `make destroy config=... env=dev` | `fabric-cicd destroy ... --env dev` | - |
      | **List Workspaces** | - | - | `python scripts/admin/utilities/list_workspaces.py` |
      
      ## Recommended Learning Path
      
      1. **Next:** [Project Generation](#project-generation) - Create your first configuration
      2. **Then:** [Local Deployment](#local-deployment) - Deploy your first workspace
      3. **Advanced:** [Docker Deployment](#docker-deployment) - CI/CD pipeline integration
      4. **Advanced:** [Git Integration](#git-integration) - Connect workspaces to repos
    code:
      language: bash
      content: |
        # Quick test: Validate a sample template
        make validate config=templates/blueprints/basic_etl.yaml
        
        # Generate your first project configuration
        python scripts/dev/generate_project.py "My Company" "First Project" --template minimal_starter
        
        # See what was created
        cat config/projects/my_company/first_project.yaml
    tips:
      - Bookmark this guide for reference
      - Keep the conda environment activated during all operations
      - "Run `make diagnose` whenever you encounter issues"
