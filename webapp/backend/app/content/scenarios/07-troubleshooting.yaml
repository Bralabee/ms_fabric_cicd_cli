# Troubleshooting Scenario
# Comprehensive guide to diagnosing and fixing common issues

id: troubleshooting
title: Troubleshooting Guide
description: |
  Master debugging with the framework's diagnostic tools. Learn to use 
  `make diagnose` for preflight checks, `python scripts/admin/preflight_check.py` 
  for detailed diagnostics, review audit logs in `audit_logs/`, and debug 
  ADO connectivity with `debug_ado_access.py`. Covers all common error scenarios.
difficulty: intermediate
estimated_duration_minutes: 20
category: troubleshooting
order: 7

prerequisites: []

learning_outcomes:
  - "Run preflight diagnostics with `make diagnose`"
  - "Use `python scripts/admin/preflight_check.py --auto-install` for comprehensive checks"
  - "Examine audit logs in `audit_logs/fabric_operations_*.jsonl`"
  - "Debug ADO access with `python scripts/admin/utilities/debug_ado_access.py`"
  - "List workspaces with `python scripts/admin/utilities/list_workspaces.py`"
  - "List workspace items with `python scripts/admin/utilities/list_workspace_items.py`"
  - Resolve authentication, permission, and configuration errors

tags:
  - troubleshooting
  - debugging
  - errors
  - authentication
  - permissions
  - make-diagnose
  - preflight-check
  - audit-logs

related_scenarios:
  - getting-started
  - docker-deployment
  - git-integration

steps:
  - id: overview
    title: Troubleshooting Strategy
    type: info
    content: |
      When something goes wrong, follow this systematic approach:
      
      ## Debugging Workflow
      
      ```
      1. Run preflight check ‚Üí make diagnose
      2. Check audit logs ‚Üí audit_logs/fabric_operations_*.jsonl
      3. Verify credentials ‚Üí .env file
      4. Test connectivity ‚Üí debug_ado_access.py
      5. Validate config ‚Üí make validate
      ```
      
      ## Diagnostic Commands
      
      | Purpose | Command |
      |---------|---------|
      | **Preflight check** | `make diagnose` |
      | **Detailed diagnostics** | `python scripts/admin/preflight_check.py --auto-install` |
      | **Docker diagnostics** | `make docker-diagnose ENVFILE=.env` |
      | **Validate config** | `make validate config=...` |
      | **Debug ADO access** | `python scripts/admin/utilities/debug_ado_access.py` |
      | **List workspaces** | `python scripts/admin/utilities/list_workspaces.py` |
      | **List workspace items** | `python scripts/admin/utilities/list_workspace_items.py --workspace "..."` |
      
      ## Common Issue Categories
      
      | Category | Likely Cause |
      |----------|--------------|
      | **Environment** | Wrong conda environment, missing packages |
      | **Authentication** | Invalid/expired credentials in .env |
      | **Permissions** | Service Principal lacks Fabric/ADO roles |
      | **Configuration** | YAML syntax errors, unresolved variables |
      | **Docker** | Build failures, mount issues, env-file missing |
      | **Git** | Empty repo, wrong branch, PAT expired |
    tips:
      - "ALWAYS start with `make diagnose` or `python scripts/admin/preflight_check.py`"
      - Check audit logs for detailed error messages

  - id: preflight-check
    title: "Step 1: Run Preflight Diagnostics"
    type: command
    content: |
      The preflight check is your FIRST troubleshooting step. It validates 
      everything automatically:
      
      ## What It Checks
      
      | Check | What It Validates |
      |-------|-------------------|
      | Environment | Python version, conda activation |
      | Fabric CLI | Installation, version |
      | Credentials | All required .env variables present |
      | Authentication | Token generation works |
      | Connectivity | Fabric API is accessible |
      | Capacity | Capacity ID is valid and accessible |
    code:
      language: bash
      content: |
        # Quick check using Make (RECOMMENDED)
        make diagnose
        
        # Detailed check with auto-install option
        python scripts/admin/preflight_check.py --auto-install
        
        # Docker environment check
        make docker-diagnose ENVFILE=.env
    expected_output: |
      ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
      ‚ïë            Fabric CLI CI/CD Preflight Check                  ‚ïë
      ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
      
      [Environment]
      ‚úì Python version: 3.11.9
      ‚úì Conda environment: fabric-cli-cicd
      
      [Fabric CLI]
      ‚úì Fabric CLI installed (version 0.1.5)
      
      [Credentials]
      ‚úì AZURE_CLIENT_ID: Set
      ‚úì AZURE_CLIENT_SECRET: Set
      ‚úì AZURE_TENANT_ID: Set
      ‚úì FABRIC_CAPACITY_ID: Set
      
      [Authentication]
      ‚úì Token generation successful
      
      [Connectivity]
      ‚úì Fabric API accessible
      ‚úì Capacity access verified
      
      ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
      ‚úÖ All preflight checks passed!
      ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    tips:
      - If any check fails, fix it before proceeding
      - "`--auto-install` will install missing Fabric CLI automatically"

  - id: audit-logs
    title: "Step 2: Check Audit Logs"
    type: command
    content: |
      Every operation is logged to `audit_logs/`. These logs contain detailed 
      error information that console output may not show.
      
      ## Log Location
      
      ```
      audit_logs/
      ‚îú‚îÄ‚îÄ fabric_operations_2025-01-15.jsonl   # Today's operations
      ‚îú‚îÄ‚îÄ fabric_operations_2025-01-14.jsonl   # Yesterday
      ‚îî‚îÄ‚îÄ fabric_cli_telemetry.jsonl           # CLI usage stats
      ```
      
      ## Log Format (JSONL)
      
      Each line is a JSON object with:
      - "`timestamp` - When it happened"
      - "`operation` - What was being done"
      - "`status` - success/failure"
      - "`error` - Error message if failed"
      - "`details` - Additional context"
    code:
      language: bash
      content: |
        # View today's audit log
        cat audit_logs/fabric_operations_$(date +%Y-%m-%d).jsonl
        
        # Find errors only
        grep '"status":"failure"' audit_logs/fabric_operations_$(date +%Y-%m-%d).jsonl
        
        # Pretty print JSON (requires jq)
        cat audit_logs/fabric_operations_$(date +%Y-%m-%d).jsonl | jq .
        
        # Last 20 entries
        tail -20 audit_logs/fabric_operations_$(date +%Y-%m-%d).jsonl
        
        # Search for specific operation
        grep "create_workspace" audit_logs/fabric_operations_$(date +%Y-%m-%d).jsonl
    expected_output: |
      # Example log entries:
      {"timestamp":"2025-01-15T10:30:00Z","operation":"deployment_start","config_file":"config/projects/acme/sales.yaml","environment":"dev","status":"success"}
      {"timestamp":"2025-01-15T10:30:05Z","operation":"create_workspace","workspace":"acme-sales-dev","status":"success","workspace_id":"abc123"}
      {"timestamp":"2025-01-15T10:30:10Z","operation":"create_item","item_type":"Lakehouse","item_name":"sales_raw","status":"failure","error":"Capacity limit exceeded"}
    tips:
      - "Use `jq` for pretty-printing JSON logs"
      - "Look for the `error` field in failed operations"
      - Logs are rotated daily for easy searching

  - id: wrong-environment
    title: "Error: Wrong Conda Environment"
    type: info
    content: |
      ## Symptom
      
      ```
      ModuleNotFoundError: No module named 'typer'
      ModuleNotFoundError: No module named 'rich'
      ModuleNotFoundError: No module named 'yaml'
      ```
      
      ## Cause
      
      Running commands in `base` or wrong conda environment.
      
      ## Solution
    code:
      language: bash
      content: |
        # Check which environment is active
        conda env list
        # Look for * next to fabric-cli-cicd
        
        # If wrong environment, activate correct one
        conda activate fabric-cli-cicd
        
        # Verify activation
        which python
        # Should show: /home/user/miniconda3/envs/fabric-cli-cicd/bin/python
        
        # Verify imports work
        python -c "import typer; import rich; import yaml; print('All imports OK')"
        
        # If environment doesn't exist, create it
        conda env create -f environment.yml
    expected_output: |
      # conda env list output (correct):
      base                     /home/user/miniconda3
      fabric-cli-cicd       *  /home/user/miniconda3/envs/fabric-cli-cicd
      
      # python path (correct):
      /home/user/miniconda3/envs/fabric-cli-cicd/bin/python
      
      # import test (correct):
      All imports OK
    tips:
      - "ALWAYS run `conda activate fabric-cli-cicd` before any command"
      - Add to your shell profile for automatic activation
    warnings:
      - This is the #1 most common issue for new users

  - id: cli-not-found
    title: "Error: fabric-cicd Command Not Found"
    type: info
    content: |
      ## Symptom
      
      ```
      fabric-cicd: command not found
      # or
      bash: fabric-cicd: command not found
      ```
      
      ## Cause
      
      Package not installed in editable mode, or entry point not registered.
      
      ## Solution
    code:
      language: bash
      content: |
        # First, ensure conda environment is active
        conda activate fabric-cli-cicd
        
        # Install package with entry points
        make install
        # OR
        pip install -e .
        
        # Verify installation
        fabric-cicd --help
        
        # Alternative: Use Python module syntax (always works)
        python -m usf_fabric_cli.cli --help
        python -m usf_fabric_cli.cli deploy config/your/config.yaml --env dev
        
        # Check if entry point is registered
        pip show usf-fabric-cli | grep Entry
    expected_output: |
      # After make install:
      Successfully installed usf-fabric-cli-1.3.0
      
      # fabric-cicd --help output:
      Usage: fabric-cicd [OPTIONS] COMMAND [ARGS]...
      
        Fabric CLI CI/CD - Enterprise Deployment Framework
      
      Options:
        --version  Show version
        --help     Show this message and exit.
      
      Commands:
        deploy    Deploy Fabric workspace from configuration file.
        destroy   Destroy Fabric workspace and all items.
        diagnose  Run preflight diagnostics.
        validate  Validate configuration file syntax and structure.
    tips:
      - "`pip install -e .` installs in \"editable\" mode (changes apply immediately)"
      - "`python -m usf_fabric_cli.cli` is equivalent and always works"

  - id: auth-failure
    title: "Error: Authentication Failures"
    type: info
    content: |
      ## Symptoms
      
      ```
      Error: Missing credentials
      Error: Token generation failed
      Error: ClientSecretCredential authentication failed
      403 Forbidden
      401 Unauthorized
      ```
      
      ## Common Causes
      
      | Error | Cause |
      |-------|-------|
      | "Missing credentials" | .env file missing or incomplete |
      | "Token generation failed" | Client secret expired/wrong |
      | "403 Forbidden" | SP lacks permissions |
      | "401 Unauthorized" | Wrong tenant ID |
      
      ## Solution
    code:
      language: bash
      content: |
        # 1. Check .env file exists
        ls -la .env
        
        # 2. Verify required variables are set (without showing values)
        python -c "
        import os
        from dotenv import load_dotenv
        load_dotenv()
        vars = ['AZURE_CLIENT_ID', 'AZURE_CLIENT_SECRET', 'AZURE_TENANT_ID', 'FABRIC_CAPACITY_ID']
        for var in vars:
            status = '‚úì SET' if os.getenv(var) else '‚úó MISSING'
            print(f'{var}: {status}')
        "
        
        # 3. Test credential validation
        python -c "
        from core.secrets import FabricSecrets
        s = FabricSecrets.load_with_fallback()
        is_valid, msg = s.validate_fabric_auth()
        print(f'Valid: {is_valid}')
        print(f'Message: {msg}')
        "
        
        # 4. If .env is missing, create from template
        cp .env.template .env
        # Then edit .env with your credentials
    expected_output: |
      # Variable check (good):
      AZURE_CLIENT_ID: ‚úì SET
      AZURE_CLIENT_SECRET: ‚úì SET
      AZURE_TENANT_ID: ‚úì SET
      FABRIC_CAPACITY_ID: ‚úì SET
      
      # Validation (good):
      Valid: True
      Message: All credentials valid
    tips:
      - Never commit .env files to Git
      - Credentials are loaded automatically via python-dotenv
      - Check for typos in variable names
    warnings:
      - Client secrets expire - check Azure Portal if auth suddenly fails

  - id: permission-issues
    title: "Error: Service Principal Permission Errors"
    type: info
    content: |
      ## Symptoms
      
      ```
      403 Forbidden
      Error: Access denied
      Error: Unauthorized
      Error: Service principal cannot create workspaces
      ```
      
      ## Required Permissions
      
      ### Fabric Tenant Settings (Admin Portal)
      
      | Setting | Required |
      |---------|----------|
      | "Service principals can use Fabric APIs" | ‚úì Enabled |
      | "Service principals can create workspaces" | ‚úì Enabled |
      | "Service principals can use Git integration" | ‚úì Enabled (for Git) |
      
      ### Azure DevOps (for Git integration)
      
      | Permission | Required |
      |------------|----------|
      | Access level | **Basic** (NOT Stakeholder!) |
      | Project role | Contributor |
      | Repository | Contribute permission |
      
      ## Debugging
    code:
      language: bash
      content: |
        # Check if you can list workspaces (basic connectivity test)
        python scripts/admin/utilities/list_workspaces.py
        
        # Debug Azure DevOps access
        python scripts/admin/utilities/debug_ado_access.py \
          --organization "your-org" \
          --project "your-project"
        
        # List items in a workspace (verifies read access)
        python scripts/admin/utilities/list_workspace_items.py \
          --workspace "your-workspace-name"
    expected_output: |
      # list_workspaces.py (good):
      Found 3 workspaces:
      - analytics-dev
      - analytics-staging
      - analytics-prod
      
      # debug_ado_access.py (good):
      ‚úì PAT authentication successful
      ‚úì Organization accessible
      ‚úì Project accessible
      ‚úì Service Principal access level: Basic
    warnings:
      - Stakeholder access level in ADO is READ-ONLY
      - Most deployment failures are permission-related
      - Check BOTH Fabric tenant settings AND ADO permissions

  - id: capacity-issues
    title: "Error: Capacity Assignment Failures"
    type: info
    content: |
      ## Symptoms
      
      ```
      Error: Capacity not found
      Error: Cannot assign workspace to capacity
      Error: Capacity limit exceeded
      Error: No available capacity
      ```
      
      ## Common Causes
      
      | Error | Cause | Solution |
      |-------|-------|----------|
      | "Capacity not found" | Wrong capacity ID | Verify GUID in Azure Portal |
      | "Cannot assign" | SP not capacity admin | Add SP as capacity admin |
      | "Limit exceeded" | F2 trial exhausted | Delete workspaces or upgrade |
      | "No available" | Capacity paused | Resume capacity in Azure |
      
      ## Solution
    code:
      language: bash
      content: |
        # 1. Verify capacity ID in .env
        grep FABRIC_CAPACITY_ID .env
        
        # 2. List existing workspaces (shows capacity usage)
        python scripts/admin/utilities/list_workspaces.py
        
        # 3. Check capacity in Azure Portal:
        #    - Go to portal.azure.com
        #    - Search "Microsoft Fabric"
        #    - Find your capacity
        #    - Verify: Status = Active, copy the Resource ID/GUID
        
        # 4. Update .env with correct capacity ID
        echo "FABRIC_CAPACITY_ID=xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx" >> .env
    tips:
      - Capacity ID is a GUID, not a name
      - "F2 trial: ~3 workspaces max"
      - "F4: ~5 workspaces"
      - Paused capacities cannot be used

  - id: yaml-errors
    title: "Error: Configuration Validation Errors"
    type: info
    content: |
      ## Symptoms
      
      ```
      Error: Configuration validation failed
      Error: YAML syntax error
      Error: Missing required field
      Error: Variable not found: ${VAR_NAME}
      ```
      
      ## Common YAML Mistakes
      
      | Error | Cause | Fix |
      |-------|-------|-----|
      | Indentation error | Tabs instead of spaces | Use 2 spaces |
      | Special chars | Unquoted `:`, `#`, `@` | Quote the string |
      | Missing variable | ${VAR} not in .env | Add to .env or use default |
      | Wrong structure | Copy-paste error | Check template format |
      
      ## Solution
    code:
      language: bash
      content: |
        # 1. Validate YAML syntax (basic)
        python -c "import yaml; yaml.safe_load(open('config/projects/your/config.yaml'))"
        
        # 2. Validate with framework (comprehensive)
        make validate config=config/projects/your/config.yaml
        
        # 3. Find unresolved environment variables
        grep '\${' config/projects/your/config.yaml
        
        # 4. Check if those variables are in .env
        cat .env | grep -E "VAR1|VAR2|VAR3"
        
        # 5. Docker validation
        make docker-validate config=config/projects/your/config.yaml ENVFILE=.env
    expected_output: |
      # Good validation output:
      ‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
      ‚ïë              Configuration Validation                        ‚ïë
      ‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù
      
      Loading: config/projects/your/config.yaml
      
      ‚úì YAML syntax valid
      ‚úì Required fields present
      ‚úì Environment variables resolved (4 variables)
      ‚úì Jinja2 template syntax valid
      
      ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
      ‚úÖ Configuration is valid!
      ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
    tips:
      - Use a YAML linter in your IDE (VS Code YAML extension)
      - Always validate before deploying

  - id: docker-errors
    title: "Error: Docker Build/Run Failures"
    type: info
    content: |
      ## Symptoms
      
      ```
      Error during docker build
      ERROR [internal] load metadata
      Error: Cannot connect to Docker daemon
      Error: ENVFILE not found
      ```
      
      ## Common Causes & Solutions
      
      | Error | Cause | Solution |
      |-------|-------|----------|
      | "Cannot connect" | Docker not running | Start Docker Desktop/daemon |
      | "Load metadata" | Network issues | Check internet, retry |
      | "ENVFILE not found" | Wrong path | Use `ENVFILE=.env` |
      | "Disk space" | Docker cache full | `docker system prune -a` |
      
      ## Solution
    code:
      language: bash
      content: |
        # 1. Check Docker is running
        docker ps
        
        # 2. Clean up Docker resources
        docker system prune -a
        
        # 3. Check disk space
        docker system df
        df -h
        
        # 4. Build with verbose output
        docker build -t fabric-cli-cicd . --progress=plain
        
        # 5. Test container directly
        docker run --rm fabric-cli-cicd fab --version
        
        # 6. Verify env file
        ls -la .env
        
        # 7. Run with explicit env file
        make docker-deploy config=... env=dev ENVFILE=.env
    tips:
      - "Build with `--progress=plain` for detailed output"
      - "Use `docker system df` to check disk usage"
      - "Default ENVFILE is `.env` - override for different clients"

  - id: git-errors
    title: "Error: Git Connection Failures"
    type: info
    content: |
      ## Symptoms
      
      ```
      Error: Git connection failed
      Error: Repository not found
      Error: Repository is empty
      Error: Branch not found
      Error: 401 Unauthorized (Git)
      ```
      
      ## Common Causes & Solutions
      
      | Error | Cause | Solution |
      |-------|-------|----------|
      | "Repository is empty" | 0 commits in repo | Run `init_ado_repo.py` |
      | "Not found" | Typo in URL | Verify git_repo in YAML |
      | "Branch not found" | Branch doesn't exist | Create branch or fix YAML |
      | "401 Unauthorized" | PAT expired/wrong | Generate new PAT |
      | "Access denied" | SP not Contributor | Add to ADO project |
      
      ## Solution
    code:
      language: bash
      content: |
        # 1. Debug ADO access first
        python scripts/admin/utilities/debug_ado_access.py \
          --organization "your-org" \
          --project "your-project"
        
        # 2. Initialize empty repository
        python scripts/admin/utilities/init_ado_repo.py \
          --organization "your-org" \
          --project "your-project" \
          --repository "your-repo"
        
        # 3. Check remote branches
        git ls-remote --heads https://dev.azure.com/your-org/your-project/_git/your-repo
        
        # 4. Verify PAT in .env
        grep AZURE_DEVOPS_PAT .env
    expected_output: |
      # debug_ado_access.py (good):
      ‚úì PAT authentication successful
      ‚úì Organization 'your-org' accessible
      ‚úì Project 'your-project' accessible
      ‚úì Service Principal access level: Basic
      
      # init_ado_repo.py (good):
      ‚úì Repository 'your-repo' initialized
      ‚úì Branch 'main' created
      ‚úì Initial README committed
    tips:
      - Fabric cannot connect to repositories with 0 commits
      - PAT scope needs "Code (Read & Write)"

  - id: utility-scripts
    title: "Reference: All Utility Scripts"
    type: info
    content: |
      ## Diagnostic Scripts
      
      | Script | Purpose |
      |--------|---------|
      | `scripts/admin/preflight_check.py` | Comprehensive environment validation |
      | `scripts/admin/utilities/debug_ado_access.py` | Test Azure DevOps connectivity |
      | `scripts/admin/utilities/list_workspaces.py` | List all accessible workspaces |
      | `scripts/admin/utilities/list_workspace_items.py` | List items in a workspace |
      
      ## Repository Scripts
      
      | Script | Purpose |
      |--------|---------|
      | `scripts/admin/utilities/init_ado_repo.py` | Initialize empty ADO repository |
      
      ## Deployment Scripts
      
      | Script | Purpose |
      |--------|---------|
      | `scripts/dev/generate_project.py` | Generate project config from template |
      | `scripts/admin/bulk_destroy.py` | Bulk delete workspaces from list |
    code:
      language: bash
      content: |
        # Full syntax for each script:
        
        # Preflight check
        python scripts/admin/preflight_check.py --auto-install
        
        # Debug ADO access
        python scripts/admin/utilities/debug_ado_access.py \
          --organization "org" \
          --project "project"
        
        # List workspaces
        python scripts/admin/utilities/list_workspaces.py
        
        # List workspace items
        python scripts/admin/utilities/list_workspace_items.py \
          --workspace "workspace-name"
        
        # Initialize ADO repo
        python scripts/admin/utilities/init_ado_repo.py \
          --organization "org" \
          --project "project" \
          --repository "repo" \
          --branch "main"
        
        # Generate project
        python scripts/dev/generate_project.py "Org Name" "Project Name" \
          --template basic_etl
        
        # Bulk destroy
        python scripts/admin/bulk_destroy.py workspace_list.txt
    tips:
      - "All scripts have `--help` for additional options"
      - Scripts work in both local and Docker environments

  - id: getting-help
    title: "Getting Help & Resources"
    type: info
    content: |
      ## Documentation Resources
      
      | Resource | Location |
      |----------|----------|
      | Main README | `README.md` |
      | CLI Walkthrough | `docs/01_User_Guides/02_CLI_Walkthrough.md` |
      | Blueprint Catalog | `docs/BLUEPRINT_CATALOG.md` |
      | Troubleshooting | `docs/TROUBLESHOOTING.md` |
      
      ## Debug Information to Collect
      
      When reporting issues, gather:
      
      1. Preflight check output
      2. Relevant audit log entries
      3. Configuration file (REDACT SECRETS!)
      4. Full error message and stack trace
      5. Python and Fabric CLI versions
    code:
      language: bash
      content: |
        # Collect all debug info to a file
        echo "=== Preflight Check ===" > debug_info.txt
        python scripts/admin/preflight_check.py >> debug_info.txt 2>&1
        
        echo "\n=== Version Info ===" >> debug_info.txt
        python --version >> debug_info.txt
        fab --version >> debug_info.txt 2>&1
        
        echo "\n=== Recent Audit Logs ===" >> debug_info.txt
        tail -50 audit_logs/fabric_operations_$(date +%Y-%m-%d).jsonl >> debug_info.txt 2>&1
        
        echo "\n=== Environment Variables (names only) ===" >> debug_info.txt
        python -c "
        import os
        for var in ['AZURE_CLIENT_ID', 'AZURE_CLIENT_SECRET', 'AZURE_TENANT_ID', 'FABRIC_CAPACITY_ID']:
            status = 'SET' if os.getenv(var) else 'MISSING'
            print(f'{var}: {status}')
        " >> debug_info.txt
        
        echo "Debug info saved to debug_info.txt"
    tips:
      - ALWAYS redact credentials before sharing debug info
      - Include the FULL error message, not just a summary

  - id: next-steps
    title: "üõ†Ô∏è Troubleshooting Complete!"
    type: info
    content: |
      You now have all the tools to diagnose and fix common issues!
      
      ## Quick Reference
      
      | Problem | First Step |
      |---------|------------|
      | Anything | `make diagnose` |
      | Authentication | Check `.env`, run preflight |
      | Permissions | `debug_ado_access.py` |
      | Config errors | `make validate config=...` |
      | Docker issues | `docker ps`, `docker system prune` |
      | Git errors | `init_ado_repo.py`, `debug_ado_access.py` |
      
      ## Command Cheat Sheet
      
      | Command | Purpose |
      |---------|---------|
      | `make diagnose` | Quick preflight check |
      | `python scripts/admin/preflight_check.py --auto-install` | Detailed check + auto-fix |
      | `make docker-diagnose ENVFILE=.env` | Docker environment check |
      | `python scripts/admin/utilities/debug_ado_access.py` | ADO connectivity test |
      | `python scripts/admin/utilities/list_workspaces.py` | Verify workspace access |
      | `make validate config=...` | Validate config file |
      
      ## Return to Previous Scenarios
      
      - [Getting Started](#getting-started) - Environment setup
      - [Local Deployment](#local-deployment) - Deploy without Docker
      - [Docker Deployment](#docker-deployment) - Containerized deployment
      - [Git Integration](#git-integration) - Version control setup
